{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attempt_2_Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi196-wFNLWn",
        "colab_type": "code",
        "outputId": "36784818-d694-49a1-f39e-3e29e9a712fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYLkTj8hNRJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = \"/content/drive/My Drive/RottenTom_Sentiment-analysis/Data/train.tsv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqFEUiB9Nh8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xmOs9lKNk28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(PATH,sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIjK-HBUNtro",
        "colab_type": "code",
        "outputId": "517242ab-5577-4b3e-9cb0-a475b86baca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdCco1HGNvc6",
        "colab_type": "code",
        "outputId": "a963ce7b-3542-4acf-e92f-643d91a6680c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "data.Sentiment.value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa840abda20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFXxJREFUeJzt3X+sXOWd3/H3J/aSkLSACbcWteka\nKVYighoCV+AVVZUNjbnAKuaPJIJdrS3k4kpAN2krdZ2tKmtJkIhUlS5SgmQFJ3a0G4fQjbA2Jq5l\nkl1tK4gvCYUYQn1DYLHFj7vYQHfZwJp8+8c8rmd9rrnjH/hc4vdLGs053+c5Z54ZzP3MnPPMnFQV\nkiQNe1ffA5AkzT2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkd8/sewLE655xz\nasmSJX0PQ5LeMR5++OG/rqqxUfq+Y8NhyZIlTE5O9j0MSXrHSPLMqH09rCRJ6jAcJEkdhoMkqcNw\nkCR1jBQOSf5dkl1JfpLkm0nek+T8JA8lmUryrSSntb7vbutTrX3J0H4+3+pPJrlyqD7RalNJ1p7o\nJylJOjqzhkOSRcDvAeNVdSEwD7gO+BJwR1V9ANgPrG6brAb2t/odrR9JLmjbfRiYAL6SZF6SecCX\ngauAC4DrW19JUk9GPaw0Hzg9yXzgvcBzwMeBe1v7RuDatryirdPar0iSVt9cVa9X1c+BKeDSdpuq\nqqeq6g1gc+srSerJrOFQVXuB/wL8FYNQeAV4GHi5qg60bnuARW15EfBs2/ZA6//+4fph2xyp3pFk\nTZLJJJPT09OjPD9J0jGY9UtwSRYweCd/PvAy8G0Gh4VOuqpaD6wHGB8fP66LXy9Z+90TMqbj9fTt\n1/Q9BEnqGOWw0r8Cfl5V01X198CfApcDZ7XDTACLgb1teS9wHkBrPxN4abh+2DZHqkuSejJKOPwV\nsCzJe9u5gyuAx4HvA59qfVYB97XlLW2d1v5AVVWrX9dmM50PLAV+COwElrbZT6cxOGm95fifmiTp\nWM16WKmqHkpyL/Aj4ADwYwaHdr4LbE7yxVa7u21yN/CNJFPAPgZ/7KmqXUnuYRAsB4Cbq+pNgCS3\nANsYzITaUFW7TtxTlCQdrZF+eK+q1gHrDis/xWCm0eF9fwF8+gj7uQ24bYb6VmDrKGORJL39/Ia0\nJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiS\nOgwHSVKH4SBJ6jAcJEkdhoMkqWPWcEjywSSPDN1eTfK5JGcn2Z5kd7tf0PonyZ1JppI8muTioX2t\nav13J1k1VL8kyWNtmzvbtaolST2ZNRyq6smquqiqLgIuAV4DvgOsBXZU1VJgR1sHuApY2m5rgLsA\nkpzN4FKjlzG4vOi6g4HS+tw4tN3ECXl2kqRjcrSHla4AflZVzwArgI2tvhG4ti2vADbVwIPAWUnO\nBa4EtlfVvqraD2wHJlrbGVX1YFUVsGloX5KkHhxtOFwHfLMtL6yq59ry88DCtrwIeHZomz2t9lb1\nPTPUO5KsSTKZZHJ6evoohy5JGtXI4ZDkNOCTwLcPb2vv+OsEjmtGVbW+qsaranxsbOztfjhJOmUd\nzSeHq4AfVdULbf2FdkiIdv9iq+8FzhvabnGrvVV98Qx1SVJPjiYcrufQISWALcDBGUergPuG6ivb\nrKVlwCvt8NM2YHmSBe1E9HJgW2t7NcmyNktp5dC+JEk9mD9KpyTvAz4B/Juh8u3APUlWA88An2n1\nrcDVwBSDmU03AFTVviRfAHa2frdW1b62fBPwdeB04P52kyT1ZKRwqKq/Bd5/WO0lBrOXDu9bwM1H\n2M8GYMMM9UngwlHGIkl6+/kNaUlSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJ\nUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVLHSOGQ5Kwk9yb5aZInkvxGkrOT\nbE+yu90vaH2T5M4kU0keTXLx0H5Wtf67k6waql+S5LG2zZ3tWtKSpJ6M+snhj4DvVdWHgI8ATwBr\ngR1VtRTY0dYBrgKWttsa4C6AJGcD64DLgEuBdQcDpfW5cWi7ieN7WpKk4zFrOCQ5E/iXwN0AVfVG\nVb0MrAA2tm4bgWvb8gpgUw08CJyV5FzgSmB7Ve2rqv3AdmCitZ1RVQ+2609vGtqXJKkHo3xyOB+Y\nBr6W5MdJvprkfcDCqnqu9XkeWNiWFwHPDm2/p9Xeqr5nhnpHkjVJJpNMTk9PjzB0SdKxGCUc5gMX\nA3dV1UeBv+XQISQA2jv+OvHD+4eqan1VjVfV+NjY2Nv9cJJ0yholHPYAe6rqobZ+L4OweKEdEqLd\nv9ja9wLnDW2/uNXeqr54hrokqSezhkNVPQ88m+SDrXQF8DiwBTg442gVcF9b3gKsbLOWlgGvtMNP\n24DlSRa0E9HLgW2t7dUky9ospZVD+5Ik9WD+iP3+LfDHSU4DngJuYBAs9yRZDTwDfKb13QpcDUwB\nr7W+VNW+JF8AdrZ+t1bVvrZ8E/B14HTg/naTJPVkpHCoqkeA8RmarpihbwE3H2E/G4ANM9QngQtH\nGYsk6e3nN6QlSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1\nGA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHSOFQ5KnkzyW5JEkk612dpLtSXa3+wWtniR3JplK\n8miSi4f2s6r1351k1VD9krb/qbZtTvQTlSSN7mg+OfxmVV1UVQcvF7oW2FFVS4EdbR3gKmBpu60B\n7oJBmADrgMuAS4F1BwOl9blxaLuJY35GkqTjdjyHlVYAG9vyRuDaofqmGngQOCvJucCVwPaq2ldV\n+4HtwERrO6OqHmzXn940tC9JUg9GDYcC/keSh5OsabWFVfVcW34eWNiWFwHPDm27p9Xeqr5nhnpH\nkjVJJpNMTk9Pjzh0SdLRmj9iv39RVXuT/BNge5KfDjdWVSWpEz+8f6iq1gPrAcbHx9/2x5OkU9VI\nnxyqam+7fxH4DoNzBi+0Q0K0+xdb973AeUObL261t6ovnqEuSerJrOGQ5H1J/vHBZWA58BNgC3Bw\nxtEq4L62vAVY2WYtLQNeaYeftgHLkyxoJ6KXA9ta26tJlrVZSiuH9iVJ6sEoh5UWAt9ps0vnA39S\nVd9LshO4J8lq4BngM63/VuBqYAp4DbgBoKr2JfkCsLP1u7Wq9rXlm4CvA6cD97ebJKkns4ZDVT0F\nfGSG+kvAFTPUC7j5CPvaAGyYoT4JXDjCeCVJJ4HfkJYkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnq\nMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1jBwOSeYl\n+XGSP2vr5yd5KMlUkm8lOa3V393Wp1r7kqF9fL7Vn0xy5VB9otWmkqw9cU9PknQsjuaTw2eBJ4bW\nvwTcUVUfAPYDq1t9NbC/1e9o/UhyAXAd8GFgAvhKC5x5wJeBq4ALgOtbX0lST0YKhySLgWuAr7b1\nAB8H7m1dNgLXtuUVbZ3WfkXrvwLYXFWvV9XPgSng0nabqqqnquoNYHPrK0nqyaifHP4b8B+BX7b1\n9wMvV9WBtr4HWNSWFwHPArT2V1r//18/bJsj1TuSrEkymWRyenp6xKFLko7WrOGQ5LeAF6vq4ZMw\nnrdUVeuraryqxsfGxvoejiT9ypo/Qp/LgU8muRp4D3AG8EfAWUnmt08Hi4G9rf9e4DxgT5L5wJnA\nS0P1g4a3OVJdktSDWT85VNXnq2pxVS1hcEL5gar6HeD7wKdat1XAfW15S1untT9QVdXq17XZTOcD\nS4EfAjuBpW3202ntMbackGcnSTomo3xyOJLfBzYn+SLwY+DuVr8b+EaSKWAfgz/2VNWuJPcAjwMH\ngJur6k2AJLcA24B5wIaq2nUc45IkHaejCoeq+gHwg7b8FIOZRof3+QXw6SNsfxtw2wz1rcDWoxmL\nJOnt4zekJUkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgO\nkqQOw0GS1HE8P9mtXxFL1n637yEA8PTt1/Q9BEmNnxwkSR2GgySpw3CQJHXMGg5J3pPkh0n+d5Jd\nSf6w1c9P8lCSqSTfatd/pl0j+lut/lCSJUP7+nyrP5nkyqH6RKtNJVl74p+mJOlojPLJ4XXg41X1\nEeAiYCLJMuBLwB1V9QFgP7C69V8N7G/1O1o/klzA4HrSHwYmgK8kmZdkHvBl4CrgAuD61leS1JNZ\nw6EG/qat/lq7FfBx4N5W3whc25ZXtHVa+xVJ0uqbq+r1qvo5MMXgGtSXAlNV9VRVvQFsbn0lST0Z\n6ZxDe4f/CPAisB34GfByVR1oXfYAi9ryIuBZgNb+CvD+4fph2xypPtM41iSZTDI5PT09ytAlScdg\npHCoqjer6iJgMYN3+h96W0d15HGsr6rxqhofGxvrYwiSdEo4qtlKVfUy8H3gN4Czkhz8Et1iYG9b\n3gucB9DazwReGq4fts2R6pKknowyW2ksyVlt+XTgE8ATDELiU63bKuC+trylrdPaH6iqavXr2mym\n84GlwA+BncDSNvvpNAYnrbeciCcnSTo2o/x8xrnAxjar6F3APVX1Z0keBzYn+SLwY+Du1v9u4BtJ\npoB9DP7YU1W7ktwDPA4cAG6uqjcBktwCbAPmARuqatcJe4aSpKM2azhU1aPAR2eoP8Xg/MPh9V8A\nnz7Cvm4DbpuhvhXYOsJ4JUkngd+QliR1+Kus0hB/oVYa8JODJKnDcJAkdRgOkqQOw0GS1GE4SJI6\nDAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6hjlGtLnJfl+kseT\n7Ery2VY/O8n2JLvb/YJWT5I7k0wleTTJxUP7WtX6706yaqh+SZLH2jZ3Jsnb8WQlSaMZ5ZPDAeA/\nVNUFwDLg5iQXAGuBHVW1FNjR1gGuApa22xrgLhiECbAOuIzB5UXXHQyU1ufGoe0mjv+pSZKO1azh\nUFXPVdWP2vL/BZ4AFgErgI2t20bg2ra8AthUAw8CZyU5F7gS2F5V+6pqP7AdmGhtZ1TVg1VVwKah\nfUmSenBU5xySLAE+CjwELKyq51rT88DCtrwIeHZosz2t9lb1PTPUZ3r8NUkmk0xOT08fzdAlSUdh\n5HBI8o+A/w58rqpeHW5r7/jrBI+to6rWV9V4VY2PjY293Q8nSaeskcIhya8xCIY/rqo/beUX2iEh\n2v2Lrb4XOG9o88Wt9lb1xTPUJUk9GWW2UoC7gSeq6r8ONW0BDs44WgXcN1Rf2WYtLQNeaYeftgHL\nkyxoJ6KXA9ta26tJlrXHWjm0L0lSD+aP0Ody4HeBx5I80mp/ANwO3JNkNfAM8JnWthW4GpgCXgNu\nAKiqfUm+AOxs/W6tqn1t+Sbg68DpwP3tJknqyazhUFV/CRzpewdXzNC/gJuPsK8NwIYZ6pPAhbON\nRZJ0cvgNaUlSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2G\ngySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVLHKNeQ3pDkxSQ/GaqdnWR7kt3tfkGrJ8mdSaaSPJrk\n4qFtVrX+u5OsGqpfkuSxts2d7TrSkqQejfLJ4evAxGG1tcCOqloK7GjrAFcBS9ttDXAXDMIEWAdc\nBlwKrDsYKK3PjUPbHf5YkqSTbNZwqKq/APYdVl4BbGzLG4Frh+qbauBB4Kwk5wJXAtural9V7Qe2\nAxOt7YyqerBde3rT0L4kST051nMOC6vqubb8PLCwLS8Cnh3qt6fV3qq+Z4b6jJKsSTKZZHJ6evoY\nhy5Jms1xn5Bu7/jrBIxllMdaX1XjVTU+NjZ2Mh5Skk5J849xuxeSnFtVz7VDQy+2+l7gvKF+i1tt\nL/Cxw+o/aPXFM/SX1LMla7/b9xAAePr2a/oewinpWD85bAEOzjhaBdw3VF/ZZi0tA15ph5+2AcuT\nLGgnopcD21rbq0mWtVlKK4f2JUnqyayfHJJ8k8G7/nOS7GEw6+h24J4kq4FngM+07luBq4Ep4DXg\nBoCq2pfkC8DO1u/Wqjp4kvsmBjOiTgfubzdJUo9mDYequv4ITVfM0LeAm4+wnw3Ahhnqk8CFs41D\nknTy+A1pSVKH4SBJ6jjW2UqSdMo4FWdu+clBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1\nGA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKljzoRDkokkTyaZSrK27/FI0qlsToRDknnA\nl4GrgAuA65Nc0O+oJOnUNSfCAbgUmKqqp6rqDWAzsKLnMUnSKStV1fcYSPIpYKKq/nVb/13gsqq6\n5bB+a4A1bfWDwJMndaBd5wB/3fMY5gpfi0N8LQ7xtThkLrwWv15VY6N0fEddJrSq1gPr+x7HQUkm\nq2q873HMBb4Wh/haHOJrccg77bWYK4eV9gLnDa0vbjVJUg/mSjjsBJYmOT/JacB1wJaexyRJp6w5\ncVipqg4kuQXYBswDNlTVrp6HNYo5c4hrDvC1OMTX4hBfi0PeUa/FnDghLUmaW+bKYSVJ0hxiOEiS\nOgwHSVLHnDghrXeeJJcCVVU720+dTAA/raqtPQ9Nc0SSTVW1su9x9CXJhxj80sOiVtoLbKmqJ/ob\n1eg8IX0U2n/sRcBDVfU3Q/WJqvpefyM7uZKsY/A7WPOB7cBlwPeBTwDbquq2HoenHiQ5fOp5gN8E\nHgCoqk+e9EH1KMnvA9cz+CmgPa28mME0/c1VdXtfYxuV4TCiJL8H3Aw8AVwEfLaq7mttP6qqi/sc\n38mU5DEGr8G7geeBxVX1apLTGQTnP+91gHNEkhuq6mt9j+NkSPIj4HHgq0AxCIdvMvhjSFX9eX+j\nO/mS/B/gw1X194fVTwN2VdXSfkY2Os85jO5G4JKquhb4GPCfk3y2taW3UfXjQFW9WVWvAT+rqlcB\nqurvgF/2O7Q55Q/7HsBJNA48DPwn4JWq+gHwd1X156daMDS/BP7pDPVzeYf8P+I5h9G96+ChpKp6\nOsnHgHuT/DqnXji8keS9LRwuOVhMcibvkH/4J0qSR4/UBCw8mWPpU1X9Ergjybfb/Quc2n9fPgfs\nSLIbeLbV/hnwAeCWI241h3hYaURJHgD+fVU9MlSbD2wAfqeq5vU2uJMsybur6vUZ6ucA51bVYz0M\nqxftj+CVwP7Dm4D/VVUzvXv8lZfkGuDyqvqDvsfSlyTvYnA5guET0jur6s3+RjU6w2FESRYzOJzy\n/Axtl1fV/+xhWOpZkruBr1XVX87Q9idV9ds9DEs6boaDJKnDE9KSpA7DQZLUYThIkjoMB0lSx/8D\niku7Dr86Z3EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1WcOpQ8OS6l",
        "colab_type": "code",
        "outputId": "15fa19e5-d26b-4d2e-c527-d63a77f00ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data['token_size'] = data['Phrase'].apply(lambda x: len(x.split(' ')))\n",
        "data.head()\n",
        "data['token_size'].max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKpJdVbGQEMU",
        "colab_type": "code",
        "outputId": "195e21e2-6b0b-4581-f375-892eb86870be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# sampling\n",
        "data = data.sample(n=50000)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17998</th>\n",
              "      <td>17999</td>\n",
              "      <td>784</td>\n",
              "      <td>a beer</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39832</th>\n",
              "      <td>39833</td>\n",
              "      <td>1903</td>\n",
              "      <td>have made it an exhilarating</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30578</th>\n",
              "      <td>30579</td>\n",
              "      <td>1420</td>\n",
              "      <td>a dualistic battle between good and evil</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143586</th>\n",
              "      <td>143587</td>\n",
              "      <td>7794</td>\n",
              "      <td>Ratliff 's two previous titles , Plutonium Cir...</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32888</th>\n",
              "      <td>32889</td>\n",
              "      <td>1541</td>\n",
              "      <td>never quite makes it to the boiling point , bu...</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        PhraseId  SentenceId  ... Sentiment  token_size\n",
              "17998      17999         784  ...         2           2\n",
              "39832      39833        1903  ...         4           5\n",
              "30578      30579        1420  ...         3           7\n",
              "143586    143587        7794  ...         3          20\n",
              "32888      32889        1541  ...         3          23\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whG1ZfLgQdi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab(object):\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWigbpXwRPIo",
        "colab_type": "code",
        "outputId": "19efde9a-f2bf-4fd2-db8c-968609fc4b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# construct vocab and indexing\n",
        "inputs = ConstructVocab(data['Phrase'].values.tolist())\n",
        "\n",
        "# examples of what is in the vocab\n",
        "inputs.vocab[40:50]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100-minute',\n",
              " '101',\n",
              " '102-minute',\n",
              " '103-minute',\n",
              " '104',\n",
              " '105',\n",
              " '10th-grade',\n",
              " '11',\n",
              " '110',\n",
              " '112-minute']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snnNR0fQRYH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"Phrase\"].values.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTkX2_w8SQ9O",
        "colab_type": "code",
        "outputId": "609a1c10-83e6-40dc-a7b8-4531743dbde6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "input_tensor[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4165, 5108],\n",
              " [9422, 10988, 10341, 4571, 8099],\n",
              " [4165, 7558, 5065, 5185, 9066, 4585, 8033],\n",
              " [3063,\n",
              "  21,\n",
              "  16288,\n",
              "  12857,\n",
              "  15971,\n",
              "  25,\n",
              "  2947,\n",
              "  922,\n",
              "  4585,\n",
              "  3019,\n",
              "  1036,\n",
              "  14425,\n",
              "  9584,\n",
              "  12361,\n",
              "  8657,\n",
              "  17309,\n",
              "  25,\n",
              "  6436,\n",
              "  6342,\n",
              "  25],\n",
              " [11705,\n",
              "  13159,\n",
              "  11021,\n",
              "  10341,\n",
              "  15974,\n",
              "  15798,\n",
              "  5357,\n",
              "  12619,\n",
              "  25,\n",
              "  5600,\n",
              "  11040,\n",
              "  15974,\n",
              "  15530,\n",
              "  4165,\n",
              "  9066,\n",
              "  14494,\n",
              "  8657,\n",
              "  11479,\n",
              "  11902,\n",
              "  10350,\n",
              "  13869,\n",
              "  15938,\n",
              "  30],\n",
              " [11791, 10659],\n",
              " [14667, 10341],\n",
              " [14797, 10220, 13631],\n",
              " [13239, 8785],\n",
              " [11488]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhzj5YHKSbx7",
        "colab_type": "code",
        "outputId": "6ca589f0-aa6a-4a32-9272-698b6c93a2b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(input_tensor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaxTJmC8SgCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6QGSn0cSlCZ",
        "colab_type": "code",
        "outputId": "1e4a7fa8-87bd-405b-b08e-aa7963a58946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmeYq1T_Smji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmsDBvwLSo86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnwlwmcRSqxN",
        "colab_type": "code",
        "outputId": "8b08d41a-00f3-4540-e3c0-8a612cbc5402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "input_tensor[ : 5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([4165, 5108,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0]),\n",
              " array([ 9422, 10988, 10341,  4571,  8099,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]),\n",
              " array([4165, 7558, 5065, 5185, 9066, 4585, 8033,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0]),\n",
              " array([ 3063,    21, 16288, 12857, 15971,    25,  2947,   922,  4585,\n",
              "         3019,  1036, 14425,  9584, 12361,  8657, 17309,    25,  6436,\n",
              "         6342,    25,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]),\n",
              " array([11705, 13159, 11021, 10341, 15974, 15798,  5357, 12619,    25,\n",
              "         5600, 11040, 15974, 15530,  4165,  9066, 14494,  8657, 11479,\n",
              "        11902, 10350, 13869, 15938,    30,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os9aMhe0S8d-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# convert targets to one-hot encoding vectors\n",
        "Sentiments = list(set(data.Sentiment.unique()))\n",
        "num_sentiments = len(Sentiments)\n",
        "\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(sen) & set(Sentiments) for sen in data[['Sentiment']].values]\n",
        "bin_sentiments = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_sentiments.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxc4-wmTThfq",
        "colab_type": "code",
        "outputId": "fdadb95b-baf5-413c-b6e8-564000d4879c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(target_tensor)\n",
        "# counter = 0\n",
        "# for ten in target_tensor:\n",
        "#     for i in ten:\n",
        "#       if (i == 0 or i == 1):\n",
        "#         print(i)\n",
        "#       else:\n",
        "#         print('found') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJACMcuEUITn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_sentiment = lambda t: np.argmax(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H66xJMXCUU4g",
        "colab_type": "code",
        "outputId": "18c9a7f5-5333-48ea-b294-3c1e3c604166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "get_sentiment(target_tensor[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn84kddcUZXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_dict = {0: 'negative', 1: 'somewhat negative', 2: 'neutral', \n",
        "                  3: 'somewhat positive', 4: 'positive'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh2RjKNIUrVg",
        "colab_type": "code",
        "outputId": "402cc1bb-3044-4f69-a0b5-f95864d48e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sentiment_dict[get_sentiment(target_tensor[1])]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt9o1OuFU0vr",
        "colab_type": "code",
        "outputId": "cc14f15f-2424-42ec-8bb2-fef0d02ba6da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 40000, 5000, 5000, 5000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GkOdWO8U_Ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ob8bv8EVEjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AyIpx8AVEyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xwAIpjhVGdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data instance\n",
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "\n",
        "# Data Loader instance\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZcotiBZVH-u",
        "colab_type": "code",
        "outputId": "7ed506b0-894c-467c-92bd-b8c12273eaa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "i = iter(train_dataset)\n",
        "text,label,text_len = i.next()\n",
        "print(text.shape)\n",
        "print(label.shape)\n",
        "print(text[0].shape)\n",
        "print(text[0])\n",
        "print(label[0])\n",
        "print(text_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 51])\n",
            "torch.Size([64, 5])\n",
            "torch.Size([51])\n",
            "tensor([16273,  9690,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0])\n",
            "tensor([0, 0, 1, 0, 0])\n",
            "tensor([ 2,  4, 18,  3,  1,  7, 32, 15,  2,  3,  4,  2,  3, 11,  3,  3,  3,  3,\n",
            "         8, 13,  2,  2,  6, 12,  7,  4, 12,  9,  2,  6,  2,  2,  3,  3, 16,  7,\n",
            "         3,  1, 13,  5,  8,  6, 21, 18,  2,  2,  1,  2,  3,  1,  2,  5,  3,  7,\n",
            "        23,  1,  3,  2, 21, 10,  2,  4, 25,  1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V--v74gtVKYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(SentimentGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        # self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "        self.fc = nn.Linear(self.hidden_units, 1000)\n",
        "        self.fc_2 = nn.Linear(1000, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, lens, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc_2(out)\n",
        "\n",
        "        return out, self.hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJbw418AdV8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AIJJt6pdrSx",
        "colab_type": "code",
        "outputId": "5a12a683-afb8-4de5-e62d-eb8f0bc4a71b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(len(input_tensor_train))\n",
        "print(len(input_tensor_val))\n",
        "print(len(input_tensor_test))\n",
        "len(inputs.word2idx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000\n",
            "5000\n",
            "5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17367"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ti8ySYnWm_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "TRAIN_BUFFER_SIZE = 40000 # len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = 5000 # len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = 5000 # len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = 17367 #len(inputs.word2idx)\n",
        "target_size = 5 # num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEcrwixqKgof",
        "colab_type": "code",
        "outputId": "672de454-5015-4a92-ccd7-ecac2c60258a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(inputs.word2idx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17367"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrFHG64VKh7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sort batch function to be able to use with pad_packed_sequence\n",
        "# batch elements ordered decreasingle by their length\n",
        "\n",
        "def sort_batch(X, y, lengths):\n",
        "    \"sort the batch by length\"\n",
        "    \n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVR_7sNLbIiG",
        "colab_type": "code",
        "outputId": "3dd80f2e-914a-4e8f-fff8-bc1f7bf1ae75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = 'cpu'\n",
        "model = SentimentGRU(vocab_inp_size + 1, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "output, _ = model(xs.to(device), lens, device)\n",
        "print(output.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-b7a8666306e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# device = 'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_inp_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# obtain one sample from the data iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuLBh3m5bJBk",
        "colab_type": "code",
        "outputId": "366a899c-66f2-4406-c165-88a08452a75b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SentimentGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.01,weight_decay=0.0001)\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-a6cd58d8176d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_inp_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# loss criterion and optimizer for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12gDAb2Ri8xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMPIQVY9gs-y",
        "colab_type": "code",
        "outputId": "b2d31a03-7d4f-471c-da23-416536a3b26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):        \n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.3276\n",
            "Epoch 1 Batch 100 Val. Loss 0.2447\n",
            "Epoch 1 Batch 200 Val. Loss 0.2150\n",
            "Epoch 1 Batch 300 Val. Loss 0.2532\n",
            "Epoch 1 Batch 400 Val. Loss 0.2650\n",
            "Epoch 1 Batch 500 Val. Loss 0.2670\n",
            "Epoch 1 Batch 600 Val. Loss 0.2913\n",
            "Epoch 1 Loss 0.2580 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.811805963516235 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.2473\n",
            "Epoch 2 Batch 100 Val. Loss 0.2639\n",
            "Epoch 2 Batch 200 Val. Loss 0.2433\n",
            "Epoch 2 Batch 300 Val. Loss 0.2245\n",
            "Epoch 2 Batch 400 Val. Loss 0.2362\n",
            "Epoch 2 Batch 500 Val. Loss 0.2525\n",
            "Epoch 2 Batch 600 Val. Loss 0.2661\n",
            "Epoch 2 Loss 0.2573 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.42712736129761 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.2686\n",
            "Epoch 3 Batch 100 Val. Loss 0.2551\n",
            "Epoch 3 Batch 200 Val. Loss 0.2584\n",
            "Epoch 3 Batch 300 Val. Loss 0.2553\n",
            "Epoch 3 Batch 400 Val. Loss 0.2857\n",
            "Epoch 3 Batch 500 Val. Loss 0.2529\n",
            "Epoch 3 Batch 600 Val. Loss 0.2084\n",
            "Epoch 3 Loss 0.2572 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.76656746864319 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.2681\n",
            "Epoch 4 Batch 100 Val. Loss 0.2455\n",
            "Epoch 4 Batch 200 Val. Loss 0.2323\n",
            "Epoch 4 Batch 300 Val. Loss 0.2490\n",
            "Epoch 4 Batch 400 Val. Loss 0.2751\n",
            "Epoch 4 Batch 500 Val. Loss 0.2506\n",
            "Epoch 4 Batch 600 Val. Loss 0.2596\n",
            "Epoch 4 Loss 0.2572 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.76726770401001 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.2556\n",
            "Epoch 5 Batch 100 Val. Loss 0.2375\n",
            "Epoch 5 Batch 200 Val. Loss 0.2500\n",
            "Epoch 5 Batch 300 Val. Loss 0.2722\n",
            "Epoch 5 Batch 400 Val. Loss 0.2545\n",
            "Epoch 5 Batch 500 Val. Loss 0.2696\n",
            "Epoch 5 Batch 600 Val. Loss 0.2908\n",
            "Epoch 5 Loss 0.2571 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.74809455871582 sec\n",
            "\n",
            "Epoch 6 Batch 0 Val. Loss 0.2438\n",
            "Epoch 6 Batch 100 Val. Loss 0.2352\n",
            "Epoch 6 Batch 200 Val. Loss 0.2669\n",
            "Epoch 6 Batch 300 Val. Loss 0.2921\n",
            "Epoch 6 Batch 400 Val. Loss 0.2593\n",
            "Epoch 6 Batch 500 Val. Loss 0.2497\n",
            "Epoch 6 Batch 600 Val. Loss 0.1941\n",
            "Epoch 6 Loss 0.2571 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.48092246055603 sec\n",
            "\n",
            "Epoch 7 Batch 0 Val. Loss 0.2415\n",
            "Epoch 7 Batch 100 Val. Loss 0.2442\n",
            "Epoch 7 Batch 200 Val. Loss 0.2914\n",
            "Epoch 7 Batch 300 Val. Loss 0.2729\n",
            "Epoch 7 Batch 400 Val. Loss 0.2241\n",
            "Epoch 7 Batch 500 Val. Loss 0.2482\n",
            "Epoch 7 Batch 600 Val. Loss 0.2763\n",
            "Epoch 7 Loss 0.2571 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.39604902267456 sec\n",
            "\n",
            "Epoch 8 Batch 0 Val. Loss 0.2399\n",
            "Epoch 8 Batch 100 Val. Loss 0.2565\n",
            "Epoch 8 Batch 200 Val. Loss 0.2299\n",
            "Epoch 8 Batch 300 Val. Loss 0.2257\n",
            "Epoch 8 Batch 400 Val. Loss 0.2659\n",
            "Epoch 8 Batch 500 Val. Loss 0.2664\n",
            "Epoch 8 Batch 600 Val. Loss 0.2470\n",
            "Epoch 8 Loss 0.2569 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.458385705947876 sec\n",
            "\n",
            "Epoch 9 Batch 0 Val. Loss 0.2730\n",
            "Epoch 9 Batch 100 Val. Loss 0.1967\n",
            "Epoch 9 Batch 200 Val. Loss 0.2418\n",
            "Epoch 9 Batch 300 Val. Loss 0.2475\n",
            "Epoch 9 Batch 400 Val. Loss 0.2705\n",
            "Epoch 9 Batch 500 Val. Loss 0.2424\n",
            "Epoch 9 Batch 600 Val. Loss 0.2508\n",
            "Epoch 9 Loss 0.2570 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.62168264389038 sec\n",
            "\n",
            "Epoch 10 Batch 0 Val. Loss 0.2701\n",
            "Epoch 10 Batch 100 Val. Loss 0.2461\n",
            "Epoch 10 Batch 200 Val. Loss 0.2312\n",
            "Epoch 10 Batch 300 Val. Loss 0.2298\n",
            "Epoch 10 Batch 400 Val. Loss 0.2802\n",
            "Epoch 10 Batch 500 Val. Loss 0.2457\n",
            "Epoch 10 Batch 600 Val. Loss 0.2536\n",
            "Epoch 10 Loss 0.2570 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.639631509780884 sec\n",
            "\n",
            "Epoch 11 Batch 0 Val. Loss 0.2386\n",
            "Epoch 11 Batch 100 Val. Loss 0.2578\n",
            "Epoch 11 Batch 200 Val. Loss 0.2457\n",
            "Epoch 11 Batch 300 Val. Loss 0.2451\n",
            "Epoch 11 Batch 400 Val. Loss 0.2368\n",
            "Epoch 11 Batch 500 Val. Loss 0.2542\n",
            "Epoch 11 Batch 600 Val. Loss 0.2475\n",
            "Epoch 11 Loss 0.2570 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.67249941825867 sec\n",
            "\n",
            "Epoch 12 Batch 0 Val. Loss 0.2745\n",
            "Epoch 12 Batch 100 Val. Loss 0.2728\n",
            "Epoch 12 Batch 200 Val. Loss 0.2730\n",
            "Epoch 12 Batch 300 Val. Loss 0.2355\n",
            "Epoch 12 Batch 400 Val. Loss 0.2247\n",
            "Epoch 12 Batch 500 Val. Loss 0.2628\n",
            "Epoch 12 Batch 600 Val. Loss 0.2399\n",
            "Epoch 12 Loss 0.2569 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.613614082336426 sec\n",
            "\n",
            "Epoch 13 Batch 0 Val. Loss 0.2803\n",
            "Epoch 13 Batch 100 Val. Loss 0.2501\n",
            "Epoch 13 Batch 200 Val. Loss 0.2513\n",
            "Epoch 13 Batch 300 Val. Loss 0.2604\n",
            "Epoch 13 Batch 400 Val. Loss 0.2411\n",
            "Epoch 13 Batch 500 Val. Loss 0.2531\n",
            "Epoch 13 Batch 600 Val. Loss 0.2503\n",
            "Epoch 13 Loss 0.2569 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.35086631774902 sec\n",
            "\n",
            "Epoch 14 Batch 0 Val. Loss 0.2790\n",
            "Epoch 14 Batch 100 Val. Loss 0.2357\n",
            "Epoch 14 Batch 200 Val. Loss 0.2481\n",
            "Epoch 14 Batch 300 Val. Loss 0.2532\n",
            "Epoch 14 Batch 400 Val. Loss 0.2594\n",
            "Epoch 14 Batch 500 Val. Loss 0.2523\n",
            "Epoch 14 Batch 600 Val. Loss 0.2326\n",
            "Epoch 14 Loss 0.2569 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.36096262931824 sec\n",
            "\n",
            "Epoch 15 Batch 0 Val. Loss 0.2764\n",
            "Epoch 15 Batch 100 Val. Loss 0.2310\n",
            "Epoch 15 Batch 200 Val. Loss 0.2350\n",
            "Epoch 15 Batch 300 Val. Loss 0.2564\n",
            "Epoch 15 Batch 400 Val. Loss 0.2214\n",
            "Epoch 15 Batch 500 Val. Loss 0.2430\n",
            "Epoch 15 Batch 600 Val. Loss 0.2528\n",
            "Epoch 15 Loss 0.2568 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.31515908241272 sec\n",
            "\n",
            "Epoch 16 Batch 0 Val. Loss 0.2421\n",
            "Epoch 16 Batch 100 Val. Loss 0.2283\n",
            "Epoch 16 Batch 200 Val. Loss 0.2334\n",
            "Epoch 16 Batch 300 Val. Loss 0.2583\n",
            "Epoch 16 Batch 400 Val. Loss 0.2612\n",
            "Epoch 16 Batch 500 Val. Loss 0.2664\n",
            "Epoch 16 Batch 600 Val. Loss 0.2580\n",
            "Epoch 16 Loss 0.2569 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.33651041984558 sec\n",
            "\n",
            "Epoch 17 Batch 0 Val. Loss 0.2760\n",
            "Epoch 17 Batch 100 Val. Loss 0.2170\n",
            "Epoch 17 Batch 200 Val. Loss 0.2469\n",
            "Epoch 17 Batch 300 Val. Loss 0.2470\n",
            "Epoch 17 Batch 400 Val. Loss 0.2392\n",
            "Epoch 17 Batch 500 Val. Loss 0.2595\n",
            "Epoch 17 Batch 600 Val. Loss 0.2506\n",
            "Epoch 17 Loss 0.2569 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.348970890045166 sec\n",
            "\n",
            "Epoch 18 Batch 0 Val. Loss 0.2758\n",
            "Epoch 18 Batch 100 Val. Loss 0.2336\n",
            "Epoch 18 Batch 200 Val. Loss 0.2512\n",
            "Epoch 18 Batch 300 Val. Loss 0.2718\n",
            "Epoch 18 Batch 400 Val. Loss 0.2303\n",
            "Epoch 18 Batch 500 Val. Loss 0.2315\n",
            "Epoch 18 Batch 600 Val. Loss 0.2526\n",
            "Epoch 18 Loss 0.2569 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.37594723701477 sec\n",
            "\n",
            "Epoch 19 Batch 0 Val. Loss 0.2351\n",
            "Epoch 19 Batch 100 Val. Loss 0.2693\n",
            "Epoch 19 Batch 200 Val. Loss 0.2633\n",
            "Epoch 19 Batch 300 Val. Loss 0.2354\n",
            "Epoch 19 Batch 400 Val. Loss 0.2500\n",
            "Epoch 19 Batch 500 Val. Loss 0.2608\n",
            "Epoch 19 Batch 600 Val. Loss 0.2441\n",
            "Epoch 19 Loss 0.2568 -- Train Acc. 50.0000 -- Val Acc. 50.0000\n",
            "Time taken for 1 epoch 40.34741520881653 sec\n",
            "\n",
            "Epoch 20 Batch 0 Val. Loss 0.2376\n",
            "Epoch 20 Batch 100 Val. Loss 0.2368\n",
            "Epoch 20 Batch 200 Val. Loss 0.2456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIOXbOVPcU8a",
        "colab_type": "code",
        "outputId": "e028f0be-1e86-49e6-c43f-961959e6b8e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "PATH_TO_Model = \"/content/drive/My Drive/RottenTom_Sentiment-analysis/SentimentGRUModel\"\n",
        "torch.save(model, PATH_TO_Model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SentimentGRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uemxTsMQmO7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}